{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Accept-Language': 'ko_KR,en;q=0.8', 'User-Agent': (\n",
    "    'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Mobile Safari/537.36')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 30000\n",
    "try:\n",
    "    url = 'https://m.dcinside.com/board/top12?page=' + str(number)\n",
    "    name_list = []\n",
    "    r = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    #img_link(soup, number, url)\n",
    "    number -= 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    number -= 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-13-b7f91ae5e613>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-b7f91ae5e613>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "hdr = {'Accept-Language': 'ko_KR,en;q=0.8', 'User-Agent': (\n",
    "    'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Mobile Safari/537.36')}\n",
    "\n",
    "def img_link(soup, number, url):\n",
    "    direc = \"./dcinside\" + str(number)[0]\n",
    "    if not os.path.isdir(direc):\n",
    "        os.mkdir(direc) \n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [(\"Referer\", url)]\n",
    "    urllib.request.install_opener(opener)\n",
    "    div_class = soup.find(\"div\", class_=\"writing_view_box\")\n",
    "\n",
    "    img_class = div_class.find_all(\"img\")\n",
    "    img_cnt = len(img_class)\n",
    "\n",
    "    # 이미지 파일 다운로드\n",
    "    for i in range(0, img_cnt):\n",
    "        string_img_url = str(img_class[i])\n",
    "        tmp_start_urlPoint = string_img_url.find(\"src=\")\n",
    "        tmp_end_urlPoint = string_img_url.find(\"style=\")\n",
    "        string_img_url = string_img_url[tmp_start_urlPoint + 5:tmp_end_urlPoint-2]\n",
    "        string_img_url = string_img_url.replace(\"amp;\", \"\")\n",
    "        urllib.request.urlretrieve(string_img_url, direc + \"/{}_{}.jpg\".format(number, i) )\n",
    "    \n",
    "    # \n",
    "    vid_class = div_class.find_all(\"video\")\n",
    "    for i in range(0, len(vid_class)):\n",
    "        string_vid_url = str(vid_class[i])\n",
    "        tmp_start_urlPoint = string_vid_url.find(\"src=\")\n",
    "        tmp_end_urlPoint = string_vid_url.find(\"loop=\")\n",
    "        string_vid_url = string_vid_url[tmp_start_urlPoint + 5:tmp_end_urlPoint-2]\n",
    "        string_vid_url = string_vid_url.replace(\"amp;\", \"\")\n",
    "        urllib.request.urlretrieve(string_vid_url,  direc + \"/{}_{}.gif\".format(number, img_cnt + i) )\n",
    "\n",
    "\n",
    "def debuging_request(r):\n",
    "    f = open(\"debuger.txt\", mode=\"wt\", encoding=\"utf-8\")\n",
    "    f.write(r)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    headers = {'Content-Type': 'application/json; charset=utf-8',\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/74.0.3729.169 Chrome/74.0.3729.169 Safari/537.36\"}\n",
    "    \n",
    "    number = 39999\n",
    "    while True:\n",
    "        try:\n",
    "            url = 'https://m.dcinside.com/board/top12' + str(number)\n",
    "            name_list = []\n",
    "            r = requests.get(url, headers = headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            img_link(soup, number, url)\n",
    "            number -= 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            number -= 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " headers = {'Content-Type': 'application/json; charset=utf-8',\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/74.0.3729.169 Chrome/74.0.3729.169 Safari/537.36\"}\n",
    "url = 'https://m.dcinside.com/board/top12' + str(number)\n",
    "name_list = []\n",
    "r = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "direc = \"./dcinside\" + str(number)[0]\n",
    "if not os.path.isdir(direc):\n",
    "    os.mkdir(direc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcinside IMG 크롤러입니다. dc에서 파싱할 게시글 URL을 입력해주세요\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " https://m.dcinside.com/board/top12/1458321\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "def img_link(soup, name_list, url):\n",
    "    if not os.path.isdir(\"./dcinside\"):\n",
    "        os.mkdir(\"./dcinside\") \n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [(\"Referer\", url)]\n",
    "    urllib.request.install_opener(opener)\n",
    "    div_class = soup.find(\"div\", class_=\"writing_view_box\")\n",
    "    img_class = div_class.find_all(\"img\")\n",
    "    for i in range(0, len(img_class), 1):\n",
    "        string_img_url = str(img_class[i])\n",
    "        tmp_start_urlPoint = string_img_url.find(\"src=\")\n",
    "        tmp_end_urlPoint = string_img_url.find(\"style=\")\n",
    "        string_img_url = string_img_url[tmp_start_urlPoint + 5:tmp_end_urlPoint-2]\n",
    "        string_img_url = string_img_url.replace(\"amp;\", \"\")\n",
    "        urllib.request.urlretrieve(string_img_url, \"./dcinside/\" + name_list[i])\n",
    "\n",
    "def name(soup, name_list):\n",
    "    ul_class = soup.find(\"ul\", class_=\"appending_file\")\n",
    "    a_tags = ul_class.find_all(\"a\")\n",
    "    for i in range(0, len(a_tags), 1):\n",
    "        string_name = str(a_tags[i])\n",
    "        tmp_start_namePoint = string_name.find(\">\")\n",
    "        tmp_end_namePoint = string_name.find(\"</a>\")\n",
    "        string_name = string_name[tmp_start_namePoint + 1 : tmp_end_namePoint]\n",
    "        name_list.append(string_name)\n",
    "    name_list.sort()\n",
    "\n",
    "def debuging_request(r):\n",
    "    f = open(\"debuger.txt\", mode=\"wt\", encoding=\"utf-8\")\n",
    "    f.write(r)\n",
    "    f.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    headers = {'Content-Type': 'application/json; charset=utf-8',\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/74.0.3729.169 Chrome/74.0.3729.169 Safari/537.36\"}\n",
    "    print(\"dcinside IMG 크롤러입니다. dc에서 파싱할 게시글 URL을 입력해주세요\")\n",
    "    url = input()\n",
    "    name_list = []\n",
    "    r = requests.get(url, headers = headers)\n",
    "    debuging_request(r.text)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    name(soup, name_list)\n",
    "    img_link(soup, name_list, url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
